{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ecf3b8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e001d3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T20:55:46.130423Z",
     "start_time": "2022-03-22T20:55:44.833542Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6282a1",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da33060e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T20:55:46.913838Z",
     "start_time": "2022-03-22T20:55:46.134198Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:97.0) Gecko/20100101 Firefox/97.0'}\n",
    "\n",
    "# URL\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "# request to URL\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "# Beautiful Soup object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# =============== Products Data =============================\n",
    "\n",
    "products = soup.find('ul', class_='products-listing small')\n",
    "product_list = products.find_all('article', class_='hm-product-item')\n",
    "\n",
    "# product_id\n",
    "product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "# product_category\n",
    "product_category = [p.get('data-category') for p in product_list]\n",
    "\n",
    "# product_name\n",
    "product_list = products.find_all('a', class_='link')\n",
    "product_name = [p.get_text() for p in product_list]\n",
    "\n",
    "# price\n",
    "product_list = products.find_all('span', class_='price regular')\n",
    "product_price = [p.get_text() for p in product_list]\n",
    "\n",
    "data = pd.DataFrame([product_id, product_category, product_name, product_price]).T\n",
    "data.columns = ['product_id', 'product_category', 'product_name', 'product_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7c8daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T20:55:46.947164Z",
     "start_time": "2022-03-22T20:55:46.917625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973d830",
   "metadata": {},
   "source": [
    "### Data collection by product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1a85be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T20:59:29.076196Z",
     "start_time": "2022-03-22T20:55:46.954227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product URL: https://www2.hm.com/en_us/productpage.0985159001.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1024256001.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0927964002.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1008549006.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0690449043.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1008549008.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0985159008.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0927964013.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0690449022.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1024256002.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0979945001.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1008549001.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0985159004.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1008549004.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1008549003.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0690449051.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1004199004.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0985159005.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1008110001.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0938875007.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0985159006.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1024256006.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0938875012.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1024256007.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0985159002.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0427159006.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1024256004.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1008110002.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1024256003.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1027852002.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0979945003.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1013317010.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0875105017.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.1004199002.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0811993034.html\n",
      "Product URL: https://www2.hm.com/en_us/productpage.0985197003.html\n"
     ]
    }
   ],
   "source": [
    "# empty dataframe\n",
    "df_composition_s = pd.DataFrame()\n",
    "\n",
    "# empty list to collect names of unique columns for all products composition\n",
    "aux = []\n",
    "\n",
    "# pattern dataframe with the columns I want to collect from each product if exist\n",
    "df_pattern = pd.DataFrame(columns=['Art. No.', 'Composition', 'Fit'])\n",
    "\n",
    "for i in range(len(data)):\n",
    "   \n",
    "    # API Requests\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] + '.html'\n",
    "   \n",
    "    print('Product URL: {}'.format(url))\n",
    "    \n",
    "    page = requests.get(url, headers=headers)\n",
    "\n",
    "    # Beautiful Soup object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # ================ Product Color ==================\n",
    "\n",
    "    gen_color_list = soup.find_all('a', class_='filter-option miniature active') + soup.find_all('a', class_='filter-option miniature')\n",
    "\n",
    "    # product colors\n",
    "    product_colors = [c.get('data-color') for c in gen_color_list]\n",
    "\n",
    "    # product id\n",
    "    product_id = [c.get('data-articlecode') for c in gen_color_list]\n",
    "\n",
    "    # dataframe color\n",
    "    df_color = pd.DataFrame(list(zip(product_id, product_colors)))\n",
    "    df_color.columns = ['product_id', 'product_colors']\n",
    "    \n",
    "    for j in range(len(df_color)):\n",
    "        \n",
    "        # API Requests\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j, 'product_id'] + '.html'\n",
    "\n",
    "        page = requests.get(url, headers=headers)\n",
    "\n",
    "        # Beautiful Soup object\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "        # ================ Product Name ==================\n",
    "        product_name = soup.find('h1', class_='primary product-item-headline')\n",
    "        product_name = product_name.get_text()\n",
    "        \n",
    "        # ================ Product Price ==================\n",
    "        product_price = soup.find_all('div', class_='primary-row product-item-price')\n",
    "        product_price = re.findall(r'\\d+\\.?\\d+', product_price[0].get_text())[0]\n",
    "    \n",
    "        # ================ Product Composition ==================\n",
    "\n",
    "        gen_composition_list = soup.find_all('div', class_='details-attributes-list-item')\n",
    "        gen_composition = [list(filter(None, d.get_text().split('\\n'))) for d in gen_composition_list]\n",
    "\n",
    "        df_composition = pd.DataFrame(gen_composition).T\n",
    "\n",
    "        # rename column names\n",
    "        df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "        # delete first row\n",
    "        df_composition = df_composition.iloc[1:]\n",
    "        \n",
    "        # drop columns\n",
    "        df_composition = df_composition.drop(columns=['messages.garmentLength', 'messages.waistRise', \n",
    "                                                      'messages.clothingStyle', 'Care instructions',\n",
    "                                                      'Material', 'Collection', 'Description', 'Imported', \n",
    "                                                      'Concept', 'Nice to know', 'More sustainable materials', 'Size'], axis=1, errors='ignore')\n",
    "\n",
    "        # reset index\n",
    "        df_composition = df_composition.reset_index(drop=True)\n",
    "            \n",
    "        # remove pocket lining, shell, and lining\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Pocket lining: ', '', regex=True)\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Shell: ', '', regex=True)\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Lining: ', '', regex=True)\n",
    "\n",
    "        # guarantee the same selected columns for all products\n",
    "        aux = aux + df_composition.columns.tolist()\n",
    "        df_composition = pd.concat([df_pattern, df_composition], axis=0)\n",
    "\n",
    "        # fill NA with info from the cell above\n",
    "        df_composition = df_composition.fillna(method='ffill')\n",
    "        \n",
    "        # rename columns\n",
    "        df_composition.columns = ['product_id', 'composition', 'fit']\n",
    "        df_composition['product_name'] = product_name\n",
    "        df_composition['product_price'] = product_price\n",
    "        \n",
    "        # merge composition and color dataframes\n",
    "        df_composition = pd.merge(df_composition, df_color, how='left', on='product_id')\n",
    "        \n",
    "\n",
    "        # all products details\n",
    "        df_composition_s = pd.concat([df_composition_s, df_composition], axis=0)\n",
    "    \n",
    "# extract style id and article id from product_id\n",
    "# generate style id + composition id\n",
    "df_composition_s['style_id'] = df_composition_s['product_id'].apply(lambda x: x[:-3])\n",
    "df_composition_s['article_id'] = df_composition_s['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "# scrapy datetime\n",
    "df_composition_s['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5969047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T20:59:29.091441Z",
     "start_time": "2022-03-22T20:59:29.079708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1702, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_composition_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638cfd7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T20:59:29.122513Z",
     "start_time": "2022-03-22T20:59:29.096433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_composition_s['product_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1eadc",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f15698",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-22T21:13:14.877899Z",
     "start_time": "2022-03-22T21:13:14.618731Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gsefsgrsefrserfd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20316/2351222078.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0mdf_aux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'product_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_ref\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mgsefsgrsefrserfd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;31m# #format composition data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gsefsgrsefrserfd' is not defined"
     ]
    }
   ],
   "source": [
    "df_data = df_composition_s\n",
    "\n",
    "df_data.head()\n",
    "\n",
    "# product_name\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\n', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\t  ', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace('\\t', '')\n",
    "df_data['product_name'] = df_data['product_name'].str.replace(' ', '_').str.lower() \n",
    "\n",
    "# product_price\n",
    "df_data['product_price'] = df_data['product_price'].astype(float)\n",
    "\n",
    "# product_color\n",
    "df_data['product_colors'] = df_data['product_colors'].str.replace(' ', '_').str.replace('/', '_').str.lower()\n",
    "\n",
    "# fit\n",
    "df_data['fit'] = df_data['fit'].apply(lambda x: x.replace(' ', '_').lower() if pd.notnull(x) else x)\n",
    "\n",
    "# =============== Column 'composition' has several information ======================\n",
    "\n",
    "# break the actual column 'composition' by comma into a new dataframe, df1\n",
    "df1 = df_data['composition'].str.split(',', expand=True).reset_index(drop=True)\n",
    "\n",
    "# create a new empty dataframe with the columns from 'composition': cotton | polyester | spandex | elastomultiester \n",
    "# same len as data\n",
    "df_ref = pd.DataFrame(index=np.arange(len(df_data)), columns=['cotton', 'polyester', 'spandex', 'elastomultiester'])\n",
    "\n",
    "# fill up and attach df_ref to data column by column:\n",
    "\n",
    "# check the unique values\n",
    "df1[0].unique() # it shows cotton, polyester\n",
    "df1[1].unique() # cotton, spandex, elastomultiester \n",
    "df1[2].unique() # spandex\n",
    "\n",
    "# -------------- cotton --------------\n",
    "\n",
    "df_cotton_0 = df1.loc[df1[0].str.contains('Cotton', na=True), 0]\n",
    "df_cotton_0.name = 'cotton'\n",
    "df_cotton_1 = df1.loc[df1[1].str.contains('Cotton', na=True), 1]\n",
    "df_cotton_1.name = 'cotton'\n",
    "\n",
    "df_cotton = df_cotton_0.combine_first(df_cotton_1)  # combine cotton\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_cotton], axis=1)     # concatenate with df_ref\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# -------------- polyester --------------\n",
    "\n",
    "df_polyester = df1.loc[df1[0].str.contains('Polyester', na=True), 0]\n",
    "df_polyester.name = 'polyester'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_polyester], axis=1)     # concatenate with df_ref\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# -------------- spandex --------------\n",
    "\n",
    "df_spandex_1 = df1.loc[df1[1].str.contains('Spandex', na=True), 1]\n",
    "df_spandex_1.name = 'spandex'\n",
    "df_spandex_2 = df1.loc[df1[2].str.contains('Spandex', na=True), 2]\n",
    "df_spandex_2.name = 'spandex'\n",
    "\n",
    "df_spandex = df_spandex_1.combine_first(df_spandex_2)  # combine spandex\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_spandex], axis=1)     # concatenate with df_ref\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# -------------- elastomultiester --------------\n",
    "\n",
    "df_elastomultiester = df1.loc[df1[1].str.contains('Elastomultiester', na=True), 1]\n",
    "df_elastomultiester.name = 'elastomultiester'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_elastomultiester], axis=1)     # concatenate with df_ref\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "\n",
    "# join of composition combined with product_id\n",
    "df_aux = pd.concat([df_data['product_id'].reset_index(drop=True), df_ref], axis=1) \n",
    "\n",
    "#format composition data\n",
    "df_aux['cotton'] = df_aux['cotton'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "df_aux['polyester'] = df_aux['polyester'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "df_aux['spandex'] = df_aux['spandex'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "df_aux['elastomultiester'] = df_aux['elastomultiester'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "\n",
    "# final join\n",
    "df_aux = df_aux.groupby('product_id').max().reset_index().fillna(0) # chooses max value of each column to keep\n",
    "df_data = pd.merge(df_data, df_aux, on='product_id', how='left')\n",
    "\n",
    "# drop columns\n",
    "df_data = df_data.drop(columns=['composition'], axis=1)\n",
    "\n",
    "# drop duplicates\n",
    "df_data = df_data.drop_duplicates()\n",
    "\n",
    "# reset index\n",
    "df_data = df_data.reset_index(drop=True)\n",
    "\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95b8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
